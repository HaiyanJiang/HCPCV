# Generated by using Rcpp::compileAttributes() -> do not edit by hand
# Generator token: 10BE3573-1514-4C36-9D1C-5A225CD40393

introduction_of_cpp_index <- function() {
    invisible(.Call(`_HCPCV_introduction_of_cpp_index`))
}

estimated_sigma_square <- function(Y) {
    .Call(`_HCPCV_estimated_sigma_square`, Y)
}

standardize_matrix <- function(X, D) {
    .Call(`_HCPCV_standardize_matrix`, X, D)
}

normalize_matrix <- function(X, W, normalized = FALSE) {
    .Call(`_HCPCV_normalize_matrix`, X, W, normalized)
}

sum_knorm <- function(x, k) {
    .Call(`_HCPCV_sum_knorm`, x, k)
}

cost_matrix <- function(X, W) {
    .Call(`_HCPCV_cost_matrix`, X, W)
}

seek_dp_tau <- function(L, H) {
    .Call(`_HCPCV_seek_dp_tau`, L, H)
}

findMin <- function(arr, n, minVal, minIdx) {
    invisible(.Call(`_HCPCV_findMin`, arr, n, minVal, minIdx))
}

#' The Dynamic Programming Method
#' 
#' Change-point detection algorithm for the high dimension mean change model
#' using the dynamic programming.
#' 
#' Dynamic Programming of changepoint detection in order to get all 
#' possible changepoints given a maximum number of changepoints, \code{Kmax}.
#' 
#' @param X a n*p data matrix
#' @param W the normalized scale of the data
#' @param Kmax scalar, the maximum number of changepoints
#' @examples 
#' n <- 100
#' tau2n <- c(0.1, 0.13, 0.15, 0.23, 0.25, 0.40, 0.44, 0.65, 0.76, 0.78, 0.81)
#' tau2n <- c(0.1, 0.40, 0.65, 0.8)
#' (tau_true <- floor(tau2n * n))
#' x <- gen_piecewise_const_vector(n, tau_true)
#' X <- matrix(x, n, 1)
#' # W <- estimated_sigma_square(X)
#' W <- rep(1, ncol(X))
#' Kmax <- length(tau_true)
#' tau_mat <- cp_hdmean_dp(X, W, Kmax)
#' tau_mat[Kmax, ]
cp_hdmean_dp <- function(X, W, Kmax) {
    .Call(`_HCPCV_cp_hdmean_dp`, X, W, Kmax)
}

remove_rows_of_matrix <- function(X, a) {
    .Call(`_HCPCV_remove_rows_of_matrix`, X, a)
}

init_vector_with_constant <- function(len, c) {
    .Call(`_HCPCV_init_vector_with_constant`, len, c)
}

#' Calculate the trace of \eqn{R^2} using Rcpp codes
#' 
#' Calculate the trace of \eqn{R^2}, \eqn{R^2} is correlation matrix of data X
#' 
#' It is slower compared to the same one but using R to calculate the value.
#' If we use the penalty from Yunlong Wang paper, which is calculated
#' \deqn{ penalty = p + c_0 * (trace(R^2))^{1/2} * log(n)^{1+\alpha}}
#' With 
#' \deqn{
#' trace(R^2) = 1 /(4(n-3)) \sum_{i=1}^{n-3}
#'   Z_{i}^T * (D_{-(i,i+1,i+2,i+3)})^(-1) * Z_{i+2}
#' }
#' where \eqn{ Z_{i} = X_{[i,]} - X_{[i+1,]} } }
#' 
#' @param X n*p data matrix
#' @return the value of trace(\eqn{R^2})
#' 
#' @examples
#' X = matrix(1:100, 20, 5)
#' trace_R_square_cpp(X)
#' 
trace_R_square_cpp <- function(X) {
    .Call(`_HCPCV_trace_R_square_cpp`, X)
}

#' The Optimal Partitioning Method of High Dimension Mean Change Model
#' 
#' Optimal Partitioning method of changepoint detection.
#' 
#' Change-point detection algorithm for the high dimension mean change model
#' using Optimal Partitioning.
#' 
#' @inheritParams cp_hdmean_dp
#' @param pen the penalty of the cost function
#' @return the locations of estimated change-points
#' 
#' @examples
#' n <- 100
#' tau2n <- c(0.1, 0.13, 0.15, 0.23, 0.25, 0.40, 0.44, 0.65, 0.76, 0.78, 0.81)
#' tau2n <- c(0.1, 0.40, 0.65, 0.8)
#' (tau_true <- floor(tau2n * n))
#' x <- gen_piecewise_const_vector(n, tau_true)
#' X <- matrix(x, n, 1)
#' W <- estimated_sigma_square(X)
#' # W <- rep(1, ncol(X))
#' pen <- log(n)^1.1
#' op_list <- cp_hdmean_op(X, W, pen)
#' (op_list$cptau)
#' 
cp_hdmean_op <- function(X, W, pen) {
    .Call(`_HCPCV_cp_hdmean_op`, X, W, pen)
}

cp_hdmean_pelt <- function(X, W, pen) {
    .Call(`_HCPCV_cp_hdmean_pelt`, X, W, pen)
}

#' \eqn{C(\tau^{train}; Xtest)}
#' 
#' The function of definition of \eqn{C(\tau^{train}; Xtest)}
#' 
#' \deqn{C(\tau^{train}; Xtest) = \sum_{l=0}^{L}
#'   \sum_{i=\tau_{l}+1}^{\tau{l+1}}
#'   (Xtrain_i - \bar(Xtest)_{\tau_{l}, \tau{l+1}})^{2} / W }
#' 
#' @param Xtrain, matrix with odd index, which is used to estimate tau.
#' @param Xtest, matrix with even index, used to construct the prediction error.
#' @param W, matrix with p*p, as the global normalizer, by dividide W[j]
#' @param tau, the vector of change-points, including 0, and n. 
#'   Usually tau is obtained by Xtrian, and this cv_objfun is used to 
#'   calculate the cross-validation squared loss.
#' @return mean of the cross validation error
cv_objfun <- function(Xtrain, Xtest, W, tau) {
    .Call(`_HCPCV_cv_objfun`, Xtrain, Xtest, W, tau)
}

#' \eqn{S_{xy}}, the function of \eqn{S_{xy}}
#' 
#' The function of definition of \eqn{S_{xy}}
#' 
#' \deqn{ S_{xy}(\tau(L); W) = \sum_{l=0}^{L}
#'   \sum_{i=\tau_{l}+1}^{\tau{l+1}}
#'   (x_i - \bar(x)_{\tau_{l}, \tau{l+1}})^{\top} W 
#'   (y_i - \bar(y)_{\tau_{l}, \tau{l+1}}) }
#' 
#' @inheritParams cv_objfun
#' @param X data matrix X
#' @param Y data matrix Y
#' 
#' @return the value of Sxy
#' 
Sxy_fun <- function(X, Y, W, tau) {
    .Call(`_HCPCV_Sxy_fun`, X, Y, W, tau)
}

test_matrix_plus_scalar <- function(X, a) {
    .Call(`_HCPCV_test_matrix_plus_scalar`, X, a)
}

test_pen_char_param <- function(X, penaltyform = "BIC") {
    invisible(.Call(`_HCPCV_test_pen_char_param`, X, penaltyform))
}

test_bool_param <- function(X, normalized = TRUE) {
    invisible(.Call(`_HCPCV_test_bool_param`, X, normalized))
}

test_vector_bounds <- function(H) {
    .Call(`_HCPCV_test_vector_bounds`, H)
}

test_insert_set <- function() {
    invisible(.Call(`_HCPCV_test_insert_set`))
}

test_init_vector_with_constant <- function(len = 4L, c = 6L) {
    invisible(.Call(`_HCPCV_test_init_vector_with_constant`, len, c))
}

